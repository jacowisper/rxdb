{"version":3,"file":"rx-storage.d.js","names":[],"sources":["../../../src/types/rx-storage.d.ts"],"sourcesContent":["import type { ChangeEvent } from 'event-reduce-js';\r\nimport type { RxChangeEvent } from './rx-change-event.d.ts';\r\nimport type { RxDocumentMeta } from './rx-document.d.ts';\r\nimport type { RxStorageWriteError } from './rx-error.d.ts';\r\nimport type { RxJsonSchema } from './rx-schema.d.ts';\r\nimport type { Override } from './util.d.ts';\r\n\r\n/**\r\n * The document data how it comes out of the storage instance.\r\n * Contains all meta data like revision, attachments and deleted-flag.\r\n */\r\nexport type RxDocumentData<T> = T & {\r\n\r\n    /**\r\n     * As other NoSQL databases,\r\n     * RxDB also assumes that no data is finally deleted.\r\n     * Instead the documents are stored with _deleted: true\r\n     * which means they will not be returned at queries.\r\n     */\r\n    _deleted: boolean;\r\n\r\n    /**\r\n     * The attachments meta data is stored besides to document.\r\n     */\r\n    _attachments: {\r\n        [attachmentId: string]: RxAttachmentData;\r\n    };\r\n\r\n    /**\r\n     * Contains a revision which is concatenated with a [height: number]-[identifier: string]\r\n     * like: '1-3hl4kj3l4kgj34g34glk'.\r\n     * The revision is used to detect write conflicts and have a document history.\r\n     * Revisions behave similar to couchdb revisions:\r\n     * @link https://docs.couchdb.org/en/stable/replication/conflicts.html#revision-tree\r\n\r\n    * When writing a document, you must send the correct revision in the previous-field\r\n     * to make sure that you do not cause a write conflict.\r\n     * The revision of the 'new' document-field must be created, for example via util.createRevision().\r\n     * Any revision that matches the [height]-[hash] format can be used.\r\n     */\r\n    _rev: string;\r\n    _meta: RxDocumentMeta;\r\n};\r\n\r\nexport type RxDocumentDataById<RxDocType> = {\r\n    [documentId: string]: RxDocumentData<RxDocType>;\r\n};\r\n\r\n/**\r\n * The document data how it is send to the\r\n * storage instance to save it.\r\n */\r\n// We & T here instead of in RxDocumentData to preserver indexability by keyof T which the Override breaks\r\nexport type RxDocumentWriteData<T> = T & Override<RxDocumentData<{}>, {\r\n    _attachments: {\r\n        /**\r\n         * To create a new attachment, set the write data\r\n         * To delete an attachment, leave it out on the _attachments property.\r\n         * To change an attachment, set the new write data.\r\n         * To not touch an attachment, just send the stub again\r\n         * which came out of the storage instance.\r\n         */\r\n        [attachmentId: string]: RxAttachmentData | RxAttachmentWriteData;\r\n    };\r\n}>;\r\n\r\nexport type WithDeleted<DocType> = DocType & {\r\n    _deleted: boolean;\r\n};\r\nexport type WithDeletedAndAttachments<DocType> = DocType & {\r\n    _deleted: boolean;\r\n\r\n    /**\r\n     * Here the _attachments might exist\r\n     * or might not, depending one the use case.\r\n     */\r\n    _attachments?: {\r\n        [attachmentId: string]: RxAttachmentData | RxAttachmentWriteData;\r\n    };\r\n};\r\n\r\n/**\r\n * Send to the bulkWrite() method of a storage instance.\r\n */\r\nexport type BulkWriteRow<RxDocType> = {\r\n    /**\r\n     * The current document state in the storage engine,\r\n     * assumed by the application.\r\n     * Undefined if the document is a new insert.\r\n     * Notice that we send the full document data as 'previous', not just the revision.\r\n     * The reason is that to get the previous revision you anyway have to get the full\r\n     * previous document and so it is easier to just send it all to the storage instance.\r\n     * This will later allow us to use something different then the _rev key for conflict detection\r\n     * when we implement other storage instances.\r\n     */\r\n    previous?: RxDocumentData<RxDocType>;\r\n    /**\r\n     * The new document data to be stored in the storage instance.\r\n     */\r\n    document: RxDocumentWriteData<RxDocType>;\r\n};\r\nexport type BulkWriteRowById<RxDocType> = {\r\n    [documentId: string]: BulkWriteRow<RxDocType>;\r\n};\r\n\r\n/**\r\n * After the RxStorage has processed all rows,\r\n * we have this to work with afterwards.\r\n */\r\nexport type BulkWriteRowProcessed<RxDocType> = BulkWriteRow<RxDocType> & {\r\n    document: RxDocumentData<RxDocType>;\r\n};\r\n\r\n\r\nexport type RxAttachmentData = {\r\n    /**\r\n     * Size of the attachments data\r\n     */\r\n    length: number;\r\n    /**\r\n     * Content type like 'plain/text'\r\n     */\r\n    type: string;\r\n    /**\r\n     * The hash of the attachments content.\r\n     * It is calculated by RxDB, and send to the storage.\r\n     * The only guarantee is that the digest will change when the attachments data changes.\r\n     * @link https://github.com/pouchdb/pouchdb/issues/3156#issuecomment-66831010\r\n     * @link https://github.com/pubkey/rxdb/pull/4107\r\n     */\r\n    digest: string;\r\n};\r\n\r\n/**\r\n * Data which is needed for new attachments\r\n * that are send from RxDB to the RxStorage implementation.\r\n */\r\nexport type RxAttachmentWriteData = RxAttachmentData & {\r\n    /**\r\n     * The data of the attachment. As string in base64 format.\r\n     * In the past we used Blob internally but it created many\r\n     * problems because of then we need the full data (for encryption/compression)\r\n     * so we anyway have to get the string value out of the Blob.\r\n     *\r\n     * Also using Blob has no performance benefit because in some RxStorage implementations,\r\n     * it just keeps the transaction open for longer because the Blob\r\n     * has be be read.\r\n     */\r\n    data: string;\r\n};\r\n\r\n\r\n/**\r\n * The returned data from RxStorageInstance.bulkWrite()\r\n * For better performance, we do NOT use an indexed object,\r\n * but only plain arrays. Because most of the time\r\n * RxDB anyway only need the array data and we can save performance\r\n * by not indexing the results.\r\n *\r\n * We do not longer return the written documents. We only return the errors.\r\n * This is because we construct the written docs array from the input+errors anyway\r\n * and transferring large amounts of data has bad performance when the storage\r\n * is running in a different realm like a WebWorker or remote.\r\n */\r\nexport type RxStorageBulkWriteResponse<RxDocType> = {\r\n    /**\r\n     * contains all errored writes.\r\n     */\r\n    error: RxStorageWriteError<RxDocType>[];\r\n};\r\n\r\n/**\r\n * We return a complex object instead of a single array\r\n * so we are able to add additional fields in the future.\r\n */\r\nexport type RxStorageQueryResult<RxDocType> = {\r\n    // the found documents, sort order is important.\r\n    documents: RxDocumentData<RxDocType>[];\r\n};\r\n\r\nexport type RxStorageCountResult = {\r\n    count: number;\r\n    /**\r\n     * Returns the mode which was used by the storage\r\n     * to count the documents.\r\n     * If this returns 'slow', RxDB will throw by default\r\n     * if 'allowSlowCount' is not set.\r\n     */\r\n    mode: 'fast' | 'slow';\r\n};\r\n\r\nexport type RxStorageInstanceCreationParams<RxDocType, InstanceCreationOptions> = {\r\n\r\n    /**\r\n     * A string to uniquely identify the instance of the JavaScript object\r\n     * of the RxDatabase where this RxStorageInstance belongs to.\r\n     * In most cases you would use RxDatabase.token here.\r\n     *\r\n     * This is used so that we can add caching or reuse stuff that belongs to the same RxDatabase.\r\n     * For example the BroadcastChannel that is used for event propagation between multiple browser tabs\r\n     * is cached by this token.\r\n     *\r\n     * In theory we could just use the databaseName for that. But to make it easier in unit tests\r\n     * to simulate cross-tab usage, we cannot assume that the databaseName is unique in a single\r\n     * JavaScript process. Therefore we use the instance token instead.\r\n     */\r\n    databaseInstanceToken: string;\r\n\r\n\r\n    databaseName: string;\r\n    collectionName: string;\r\n    schema: RxJsonSchema<RxDocumentData<RxDocType>>;\r\n    options: InstanceCreationOptions;\r\n    /**\r\n     * If multiInstance is true, there can be more\r\n     * then one instance of the database, for example\r\n     * when multiple browser tabs exist or more then one Node.js\r\n     * process relies on the same storage.\r\n     */\r\n    multiInstance: boolean;\r\n    password?: string | any;\r\n\r\n    /**\r\n     * Some storages can do additional checks\r\n     * that are performance expensive\r\n     * and should only be done in dev-mode.\r\n     */\r\n    devMode: boolean;\r\n};\r\n\r\nexport type ChangeStreamOptions = {\r\n\r\n    /**\r\n     * Sequence number of the first event to start with.\r\n     * If you want to get all ongoing events,\r\n     * first get the latest sequence number and input it here.\r\n     *\r\n     * Optional on changeStream,\r\n     * will start from the newest sequence.\r\n     */\r\n    startSequence?: number;\r\n    /**\r\n     * limits the amount of results\r\n     */\r\n    limit?: number;\r\n};\r\n\r\n/**\r\n * In the past we handles each RxChangeEvent by its own.\r\n * But it has been shown that this take way more performance then needed,\r\n * especially when the events get transferred over a data layer\r\n * like with WebWorkers or the BroadcastChannel.\r\n * So we now process events as bulks internally.\r\n */\r\nexport type EventBulk<EventType, CheckpointType> = {\r\n    /**\r\n     * Unique id of the bulk,\r\n     * used to detect duplicate bulks\r\n     * that have already been processed.\r\n     */\r\n    id: string;\r\n    events: EventType[];\r\n\r\n    /**\r\n     * Required for replication.\r\n     * Passing this checkpoint into getChangedDocumentsSince()\r\n     * must return all items that have been modified AFTER this write event.\r\n     */\r\n    checkpoint: CheckpointType;\r\n\r\n    /**\r\n     * The context that was given at the call to bulkWrite()\r\n     * that caused this EventBulk.\r\n     */\r\n    context: string;\r\n};\r\n\r\nexport type ChangeStreamEvent<DocType> = ChangeEvent<RxDocumentData<DocType>> & {\r\n    /**\r\n     * An integer that is increasing\r\n     * and unique per event.\r\n     * Can be used to sort events or get information\r\n     * about how many events there are.\r\n     */\r\n    sequence: number;\r\n    /**\r\n     * The value of the primary key\r\n     * of the changed document\r\n     */\r\n    id: string;\r\n};\r\n\r\nexport type RxStorageChangeEvent<RxDocType> = Omit<RxChangeEvent<RxDocType>, 'isLocal' | 'collectionName'>;\r\n\r\n/**\r\n * An example for how a RxStorage checkpoint can look like.\r\n * NOTICE: Not all implementations use this type.\r\n */\r\nexport type RxStorageDefaultCheckpoint = {\r\n    id: string;\r\n    lwt: number;\r\n};\r\n\r\n\r\n\r\n\r\nexport type CategorizeBulkWriteRowsOutput<RxDocType> = {\r\n    bulkInsertDocs: BulkWriteRowProcessed<RxDocType>[];\r\n    bulkUpdateDocs: BulkWriteRowProcessed<RxDocType>[];\r\n\r\n    errors: RxStorageWriteError<RxDocType>[];\r\n    eventBulk: EventBulk<RxStorageChangeEvent<RxDocumentData<RxDocType>>, any>;\r\n    attachmentsAdd: {\r\n        documentId: string;\r\n        attachmentId: string;\r\n        attachmentData: RxAttachmentWriteData;\r\n        digest: string;\r\n    }[];\r\n    attachmentsRemove: {\r\n        documentId: string;\r\n        attachmentId: string;\r\n        digest: string;\r\n    }[];\r\n    attachmentsUpdate: {\r\n        documentId: string;\r\n        attachmentId: string;\r\n        attachmentData: RxAttachmentWriteData;\r\n        digest: string;\r\n    }[];\r\n    /**\r\n     * Contains the non-error document row that\r\n     * has the newest _meta.lwt time.\r\n     * Empty if no successful write exists.\r\n     */\r\n    newestRow?: BulkWriteRowProcessed<RxDocType>;\r\n};\r\n"],"mappings":"","ignoreList":[]}